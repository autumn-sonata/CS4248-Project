{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71c7e43e",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5116044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN SETUP.SH BEFORE RUNNING THIS IPYNB\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB # Naive Bayes Classifier\n",
    "from sklearn.linear_model import LogisticRegression # Logistic Regression Classifier\n",
    "from sklearn.neural_network import MLPClassifier # Multi Layer Perceptron, simple Neural Network\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import ADASYN, RandomOverSampler\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81c927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42 # seed random state for comparison, testing\n",
    "PARTITION_SIZE = 500 # Adjust lower if potato PC and higher if gaming rig or want results closer to actual\n",
    "enable_all_data = True # SET TO FALSE IF PREPROCESSING TAKES A LONG TIME (True = test on PARTITION_SIZE training and PARTITION_SIZE testing samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f33710",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48002adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Jian Hui start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8090b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('raw_data/fulltrain.csv', index_col = False)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641253f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df if enable_all_data else df.sample(n=PARTITION_SIZE, random_state=SEED)\n",
    "X_train = df.iloc[:, 1] \n",
    "y_train = df.iloc[:, 0]\n",
    "\n",
    "print(X_train.head())\n",
    "print(y_train.head())\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f090821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quickload pre-processed data\n",
    "X_train = pd.read_csv('raw_data/lemma_strip_punct_stop.csv', index_col = False)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9285af76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing data: tokenize the text for NLP Machine Learning\n",
    "# Eric\n",
    "spacy_preprocess_model = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess(sentence):\n",
    "    '''\n",
    "    Preprocessing strategies:\n",
    "    1) Tokenization\n",
    "    2) Punctuation removal\n",
    "    3) Stopword removal\n",
    "    4) Lemmatization\n",
    "    5) Lowercase\n",
    "    '''\n",
    "    tokens = spacy_preprocess_model(sentence)\n",
    "    ls_sentence = [token.lemma_ for token in tokens if not token.is_punct and not token.is_stop]\n",
    "    return ls_sentence\n",
    "\n",
    "# To be used by features for feature extraction:\n",
    "X_train_ls = X_train.apply(preprocess)\n",
    "X_train_sentence = X_train_ls.apply(lambda sentence: ' '.join(sentence))\n",
    "\n",
    "# X_train_ls = X_train\n",
    "# X_train_sentence = X_train_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5ac114",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.head())\n",
    "print(X_train_ls.head())\n",
    "print(X_train_sentence.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136b5d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pre-processed data\n",
    "# compression_opts = dict(method='zip', archive_name='lemma_strip_punct_stop.csv')\n",
    "# X_train_sentence.to_csv('lemma_strip_punct_stop.zip', index=False, compression=compression_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07ca07b",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3095317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature set:\n",
    "# 1) TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), sublinear_tf=True)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdd8bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) NER? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0f8f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidation of feature sets into single vector:\n",
    "# Eric\n",
    "X_train = hstack([X_train_tfidf])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07f2107",
   "metadata": {},
   "source": [
    "### Naive Bayes Model [MultinomialNB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c952f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB().fit(X_train, y_train) # fit model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b89589e",
   "metadata": {},
   "source": [
    "### Logistic Regression Model [LogisticRegression]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4879294",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver = 'saga').fit(X_train, y_train) # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe0b24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain predictions on training data\n",
    "y_train_predicted = model.predict(X_train)\n",
    "\n",
    "# evaluate model training metrics with macro f1 score\n",
    "f1_score(y_train, y_train_predicted, average='macro') # TODO this tests the model on its already trained set..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8997e6",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47293816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST DATA \n",
    "test_df = pd.read_csv('raw_data/balancedtest.csv', index_col = False)\n",
    "test_df = test_df if enable_all_data else test_df.sample(PARTITION_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd783554",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.iloc[:, 1]\n",
    "y_test = test_df.iloc[:, 0]\n",
    "\n",
    "# print(X_test.head())\n",
    "# print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337bcfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess test data to match steps on training data\n",
    "X_test_ls = X_test.apply(preprocess)\n",
    "X_test_sentence = X_test_ls.apply(lambda sentence: ' '.join(sentence))\n",
    "\n",
    "# X_test_ls = X_test\n",
    "# X_test_sentence = X_test_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0863f80a",
   "metadata": {},
   "source": [
    "### Feature Engineering (Test Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0afa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) TF-IDF\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891b1b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidation of feature transformations into single vector\n",
    "# Eric\n",
    "X_test = hstack([X_test_tfidf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f9170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain predictions on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaluate model training metrics with macro f1 score\n",
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c4ce93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5544f381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do prediction on training data\n",
    "y_train_predicted = lr_clf.predict(X_train)\n",
    "\n",
    "# obtain training f1 score\n",
    "f1_score(y_train, y_train_predicted, average='macro') # TODO this tests the model on its already trained set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cc6c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain predictions on test data\n",
    "y_pred = lr_clf.predict(X_test)\n",
    "\n",
    "# obtain test f1 score\n",
    "f1_score(y_test, y_pred, average= 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e9e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyper Parameter tuning with GridSearchCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676ff02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Jian Hui end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f13bebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### <Group Member's name> start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0b8584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group member's code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7d8f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8843a535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e911876",
   "metadata": {},
   "outputs": [],
   "source": [
    "### <Group Member's name> end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee8d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f121ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510d5573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd6dc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55507397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc09d284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aab69b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeb89dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a87c63b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596eb93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a0c61a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
