{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71c7e43e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5116044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN SETUP.SH BEFORE RUNNING THIS IPYNB\n",
    "# REQUIREMENTS FOR SETUP.SH:\n",
    "# python 3.11.8\n",
    "# pip 23.3.1\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB # Naive Bayes Classifier\n",
    "from sklearn.linear_model import LogisticRegression # Logistic Regression Classifier\n",
    "from sklearn.neural_network import MLPClassifier # Multi Layer Perceptron, simple Neural Network\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import ADASYN, RandomOverSampler\n",
    "from scipy.sparse import hstack, csr_matrix, save_npz, load_npz\n",
    "import spacy\n",
    "import re\n",
    "import numpy as np\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectPercentile, chi2, f_regression, mutual_info_classif\n",
    "import nltk\n",
    "from readability import Readability\n",
    "# import text2emotion as te\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b81c927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42 # seed random state for comparison, testing\n",
    "PARTITION_SIZE = 500 # Adjust lower if potato PC and higher if gaming rig or want results closer to actual\n",
    "enable_all_data = True # SET TO FALSE IF PREPROCESSING TAKES A LONG TIME (True = test on PARTITION_SIZE training and PARTITION_SIZE testing samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f33710",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48002adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Jian Hui start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a8090b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A little less than a decade ago, hockey fans w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The writers of the HBO series The Sopranos too...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Despite claims from the TV news outlet to offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>After receiving 'subpar' service and experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1\n",
       "0  1  A little less than a decade ago, hockey fans w...\n",
       "1  1  The writers of the HBO series The Sopranos too...\n",
       "2  1  Despite claims from the TV news outlet to offe...\n",
       "3  1  After receiving 'subpar' service and experienc...\n",
       "4  1  After watching his beloved Seattle Mariners pr..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('raw_data/fulltrain.csv', header=None, index_col = False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "641253f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        A little less than a decade ago, hockey fans w...\n",
      "1        The writers of the HBO series The Sopranos too...\n",
      "2        Despite claims from the TV news outlet to offe...\n",
      "3        After receiving 'subpar' service and experienc...\n",
      "4        After watching his beloved Seattle Mariners pr...\n",
      "                               ...                        \n",
      "48849    The ruling Kuomintang (KMT) has claimed owners...\n",
      "48850    The Taipei city government has encouraged the ...\n",
      "48851    President Ma Ying-jeou said Friday that a park...\n",
      "48852    The families of the four people who were kille...\n",
      "48853    The Ministry of Finance will make public on Sa...\n",
      "Name: 1, Length: 48854, dtype: object\n",
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "48849    4\n",
      "48850    4\n",
      "48851    4\n",
      "48852    4\n",
      "48853    4\n",
      "Name: 0, Length: 48854, dtype: int64\n",
      "48854\n",
      "48854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0\n",
       "3    17870\n",
       "1    14047\n",
       "4     9995\n",
       "2     6942\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df if enable_all_data else df.sample(n=PARTITION_SIZE, random_state=SEED)\n",
    "\n",
    "X_train = df.iloc[:, 1] \n",
    "y_train = df.iloc[:, 0]\n",
    "X_train_unprocessed = X_train\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9285af76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing data: tokenize the text for NLP Machine Learning\n",
    "# Lemmatization, Case-folding (lowercase), Stopword removal, Punctuation removal\n",
    "# Eric\n",
    "personal_pronouns = [\"i\", \"me\", \"mine\", \"my\", \"myself\", \"our\", \"ours\", \"we\", \\\n",
    "                     \"their\", \"you\", \"your\", \"he\", \"she\", \"it\", \"its\", \"we\", \"they\", \"me\", \\\n",
    "                     \"him\", \"her\", \"us\", \"them\", \"his\", \"hers\", \"herself\", \\\n",
    "                        \"himself\", \"itself\", \"themselves\", \"ourselves\", \"yourself\", \"yourselves\"]\n",
    "spacy_preprocess_model = spacy.load(\"en_core_web_lg\")\n",
    "spacy_preprocess_model.Defaults.stop_words -= set(personal_pronouns)\n",
    "\n",
    "# def preprocess(sentence):\n",
    "#     '''\n",
    "#     Preprocessing strategies:\n",
    "#     1) Tokenization\n",
    "#     2) Punctuation removal\n",
    "#     3) Stopword removal\n",
    "#     4) Lemmatization\n",
    "#     5) Lowercase\n",
    "#     '''\n",
    "#     tokens = spacy_preprocess_model(sentence)\n",
    "#     ls_sentence = [token.lemma_.lower() for token in tokens if not (token.is_punct and token not in [\"!\", \"?\"]) and not token.is_stop]\n",
    "#     return ls_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5945f38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing data: tokenize the text for NLP Machine Learning\n",
    "# Case-folding (lowercase), Stopword removal, Punctuation removal\n",
    "\n",
    "def preprocess(sentence):\n",
    "    '''\n",
    "    Preprocessing strategies:\n",
    "    1) Tokenization\n",
    "    2) Punctuation removal\n",
    "    3) Stopword removal\n",
    "    4) Lowercase\n",
    "    '''\n",
    "    tokens = spacy_preprocess_model(sentence)\n",
    "    ls_sentence = [token.text.lower() for token in tokens if not (token.is_punct and token not in [\"!\", \"?\"]) and not token.is_stop]\n",
    "    return ls_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b12ef4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing data: tokenize the text for NLP Machine Learning\n",
    "# Case-folding (lowercase), Punctuation removal\n",
    "\n",
    "# def preprocess(sentence):\n",
    "#     '''\n",
    "#     Preprocessing strategies:\n",
    "#     1) Tokenization\n",
    "#     2) Punctuation removal\n",
    "#     3) Lowercase\n",
    "#     '''\n",
    "#     tokens = spacy_preprocess_model(sentence)\n",
    "#     ls_sentence = [token.text.lower() for token in tokens if not (token.is_punct and token not in [\"!\", \"?\"])]\n",
    "#     return ls_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfc63bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing data: tokenize the text for NLP Machine Learning\n",
    "# pos (TAG), Punctuation removal\n",
    "\n",
    "# def preprocess(sentence):\n",
    "#     '''\n",
    "#     Preprocessing strategies:\n",
    "#     1) Tokenization\n",
    "#     2) Punctuation removal\n",
    "#     3) POS tag\n",
    "#     '''\n",
    "#     tokens = spacy_preprocess_model(sentence)\n",
    "#     ls_sentence = [token.tag_ for token in tokens if not (token.is_punct and token not in [\"!\", \"?\"])]\n",
    "#     return ls_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96ab75c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be used by features for feature extraction:\n",
    "# X_train_ls = X_train.apply(preprocess)\n",
    "# X_train_sentence = X_train_ls.apply(lambda sentence: ' '.join(sentence))\n",
    "\n",
    "# X_train_ls = X_train\n",
    "# X_train_sentence = X_train_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99544445",
   "metadata": {},
   "source": [
    "### Save and load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c5103f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_sentence.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e62e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pre-processed data\n",
    "# compression_opts = dict(method='zip', archive_name='strip_punct_stop_lower.csv')\n",
    "# X_train_sentence.to_csv('strip_punct_stop_lower.zip', index=False, compression=compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f090821c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacytextblob.spacytextblob.SpacyTextBlob at 0x19b0127efd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quickload pre-processed data\n",
    "# replace 'raw_data/*.csv' with .csv file containing preprocessed data\n",
    "X_train = pd.read_csv('strip_punct_stop_lower.csv', index_col=False).iloc[:, 0]\n",
    "X_train.head()\n",
    "\n",
    "# Reload constants if preprocessing cells are not executed\n",
    "personal_pronouns = [\"i\", \"me\", \"mine\", \"my\", \"myself\", \"our\", \"ours\", \"we\", \\\n",
    "                     \"their\", \"you\", \"your\", \"he\", \"she\", \"it\", \"its\", \"we\", \"they\", \"me\", \\\n",
    "                     \"him\", \"her\", \"us\", \"them\", \"his\", \"hers\", \"herself\", \\\n",
    "                        \"himself\", \"itself\", \"themselves\", \"ourselves\", \"yourself\", \"yourselves\"]\n",
    "spacy_model = spacy.load(\"en_core_web_lg\")\n",
    "spacy_model.Defaults.stop_words -= set(personal_pronouns)\n",
    "spacy_model.add_pipe('spacytextblob')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704b2070",
   "metadata": {},
   "source": [
    "### Train-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b08f33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unprocessed, X_val_unprocessed, _, _ = train_test_split(X_train_unprocessed, y_train, test_size=0.2, random_state=SEED)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c04d7d4",
   "metadata": {},
   "source": [
    "### Feature analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6bd00ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_analysis_bar(X, y, feature_name):\n",
    "    unique_y = np.unique(y)\n",
    "    fig, axs = plt.subplots(len(unique_y), 1, figsize=(8, len(unique_y) * 4))\n",
    "    for i in unique_y:\n",
    "        indices = np.where(y == i)[0]\n",
    "        counts_i = X[indices]\n",
    "        unique_vals, counts = np.unique(counts_i, return_counts=True)\n",
    "        axs[i-1].bar(unique_vals, counts)\n",
    "        axs[i-1].set_xlabel(f'{feature_name}')\n",
    "        axs[i-1].set_ylabel(f'Frequency of {feature_name}')\n",
    "        axs[i-1].set_title(f'Distribution of {feature_name} for class {i}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/{feature_name}_analysis_plot.png')\n",
    "\n",
    "def count_analysis_scatter(X, y, feature_name):\n",
    "    unique_y = np.unique(y)\n",
    "    fig, axs = plt.subplots(len(unique_y), 1, figsize=(8, len(unique_y) * 4))\n",
    "    for i in unique_y:\n",
    "        indices = np.where(y == i)[0]\n",
    "        counts_i = X[indices]\n",
    "        unique_vals, counts = np.unique(counts_i, return_counts=True)\n",
    "        axs[i-1].scatter(unique_vals, counts)\n",
    "        axs[i-1].set_xlabel(f'{feature_name}')\n",
    "        axs[i-1].set_ylabel(f'Frequency of {feature_name}')\n",
    "        axs[i-1].set_title(f'Distribution of {feature_name} for class {i}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/{feature_name}_analysis_plot.png')\n",
    "\n",
    "def count_analysis_boxplot(X, y, feature_name):\n",
    "    unique_y = np.unique(y)\n",
    "    fig, axs = plt.subplots(len(unique_y), 1, figsize=(8, len(unique_y) * 4))\n",
    "    for i in unique_y:\n",
    "        indices = np.where(y == i)[0]\n",
    "        counts_i = X[indices]\n",
    "        unique_vals = np.unique(counts_i)\n",
    "        axs[i-1].boxplot(unique_vals)\n",
    "        axs[i-1].set_title(f'Distribution of {feature_name} for class {i}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/{feature_name}_analysis_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07ca07b",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3095317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature set:\n",
    "# 1) TF-IDF and TF\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), sublinear_tf=True)\n",
    "tf_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_train_tf = tf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "378359e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Summation of word2vec on top k words tf-idf per sentence\n",
    "k = 5\n",
    "tfidf_vectorizer_word2vec = TfidfVectorizer(sublinear_tf=True)\n",
    "tfidf_word2vec = tfidf_vectorizer_word2vec.fit_transform(X_train)\n",
    "non_zero_counts = tfidf_word2vec.getnnz(axis=1)\n",
    "\n",
    "def word2vec_select_k_best_sum(matrix, non_zero_counts):\n",
    "    res = None\n",
    "    for row in range(matrix.shape[0]):\n",
    "        # Get indexes of words\n",
    "        num_words = min(k, non_zero_counts[row])\n",
    "        row_val_idxs = matrix[row].indices\n",
    "        top_k_idx = np.argpartition(matrix[row].data, -num_words)[-num_words:]\n",
    "        indexes = row_val_idxs[top_k_idx]\n",
    "        \n",
    "        # Get words\n",
    "        words = tfidf_vectorizer_word2vec.get_feature_names_out()[indexes]\n",
    "\n",
    "        # Get summation of word vectors\n",
    "        summation_vector = np.sum(np.array([spacy_model(word).vector for word in words]), axis=0)\n",
    "        if res is None:\n",
    "            res = np.zeros([matrix.shape[0], summation_vector.shape[0]])\n",
    "        res[row] = summation_vector\n",
    "\n",
    "    return res\n",
    "\n",
    "# X_train_word2vec = word2vec_select_k_best_sum(tfidf_word2vec, non_zero_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f48d5a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Number of personal pronouns\n",
    "def count_personal_pronouns(sentence):\n",
    "    counter = 0\n",
    "    sentence_ls = sentence.split()\n",
    "    for token in sentence_ls:\n",
    "        if token in personal_pronouns:\n",
    "            counter += 1\n",
    "    return counter\n",
    "\n",
    "# X_train_count_pp = X_train.apply(count_personal_pronouns).to_numpy().reshape(-1, 1)\n",
    "# count_analysis_scatter(X_train_count_pp, y_train, \"personal_pronouns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7bdb98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Count number of words\n",
    "def count_words(sentence):\n",
    "    return len(sentence.split())\n",
    "\n",
    "# X_train_count_words = X_train_unprocessed.apply(count_words).to_numpy().reshape(-1, 1)\n",
    "# count_analysis_scatter(X_train_count_words, y_train, \"word_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc30e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Number of upper case letters\n",
    "def count_uppercase(text):\n",
    "    return len(re.findall(r\"[A-Z]\", text))\n",
    "\n",
    "# X_train_count_uppercase = X_train_unprocessed.apply(count_uppercase).to_numpy().reshape(-1, 1)\n",
    "# count_analysis_scatter(X_train_count_uppercase, y_train, \"uppercase_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7698f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Flesch Kincaid reading ease\n",
    "def flesch_kincaid(sentence):\n",
    "    if len(sentence.split()) <= 110:\n",
    "        return 65 # Standard average value for Flesch Kincaid reading ease score \n",
    "    return Readability(sentence).flesch().score\n",
    "\n",
    "# X_train_flesch = X_train_unprocessed.apply(flesch_kincaid).to_numpy().reshape(-1, 1)\n",
    "# count_analysis_boxplot(X_train_flesch, y_train, \"flesch_kincaid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0156ef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Verb counting\n",
    "def count_verbs(sentences, verb_tags=['VBZ', 'VBP', 'VBN', 'VBG', 'VBD', 'VB']):\n",
    "    res = np.zeros((len(sentences), len(verb_tags)))\n",
    "    row = 0\n",
    "    for sentence in sentences:\n",
    "        tags = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "        d = Counter(map(lambda tup: tup[1], filter(lambda tup: tup[1] in verb_tags, tags)))\n",
    "        for tag in verb_tags:\n",
    "            if tag not in d:\n",
    "                d[tag] = 0\n",
    "\n",
    "        verb_counts = np.array(list(map(lambda tup: tup[1], sorted(d.items(), key=lambda tup: tup[0])))) # Sort by tag, get counts\n",
    "        res[row] = verb_counts\n",
    "        row += 1\n",
    "    return res\n",
    "\n",
    "# X_train_count_verbs = count_verbs(X_train)\n",
    "# count_analysis_bar(X_train_count_verbs, y_train, \"verb_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff0f8f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidation of feature sets into single vector:\n",
    "# X_train = hstack([X_train_tfidf, X_train_tf, X_train_word2vec, X_train_count_pp, X_train_count_words, X_train_count_uppercase, X_train_flesch, X_train_count_verbs])\n",
    "X_train_filename = \"tfidf-tf-word2vec-pp-word-uppercase-flesch-verb\"\n",
    "# save_npz(f\"{X_train_filename}.npz\", X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07fa86f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features as sparse matrix (Download file from Google Drive)\n",
    "X_train_filename = \"tfidf-tf-word2vec-pp-word-uppercase-flesch-verb\"\n",
    "X_train = load_npz(f\"{X_train_filename}.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f945981a",
   "metadata": {},
   "source": [
    "### Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16011090",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler() # Sparse matrix\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f0f9a",
   "metadata": {},
   "source": [
    "### Feature selection: SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10c7dfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take top 10% of features by scores given by chi2\n",
    "feature_selector = SelectPercentile(f_regression) # TODO try with mutual_info_classif instead of f_regression\n",
    "X_train = feature_selector.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ce5211",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7b26eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=SEED)\n",
    "X_train, y_train = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a609fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADASYN\n",
    "# ada = ADASYN(random_state=SEED)\n",
    "# X_train, y_train = ada.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4eaf66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTEENN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83844d2d",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07f2107",
   "metadata": {},
   "source": [
    "### Naive Bayes Model [MultinomialNB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c952f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MultinomialNB().fit(X_train, y_train) # fit model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb850e0c",
   "metadata": {},
   "source": [
    "### Random Forest Model [RandomForestClassifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d237fc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestClassifier(n_estimators=500).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b89589e",
   "metadata": {},
   "source": [
    "### Logistic Regression Model [LogisticRegression]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4879294",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver = 'saga', max_iter=3000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac9bd3c",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4ae2fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature engineering on X_val\n",
    "val_tfidf_word2vec = tfidf_vectorizer_word2vec.transform(X_val)\n",
    "non_zero_counts = val_tfidf_word2vec.getnnz(axis=1)\n",
    "\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
    "X_val_tf = tf_vectorizer.transform(X_val)\n",
    "X_val_word2vec = word2vec_select_k_best_sum(val_tfidf_word2vec, non_zero_counts)\n",
    "X_val_count_pp = X_val.apply(count_personal_pronouns).to_numpy().reshape(-1, 1)\n",
    "X_val_count_words = X_val_unprocessed.apply(count_words).to_numpy().reshape(-1, 1)\n",
    "X_val_count_uppercase = X_val_unprocessed.apply(count_uppercase).to_numpy().reshape(-1, 1)\n",
    "X_val_flesch = X_val_unprocessed.apply(flesch_kincaid).to_numpy().reshape(-1, 1)\n",
    "X_val_count_verbs = count_verbs(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1e6b93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidation of feature sets:\n",
    "X_val_final = hstack([X_val_tfidf, X_val_tf, X_val_word2vec, X_val_count_pp, X_val_count_words, X_val_count_uppercase, X_val_flesch, X_val_count_verbs])\n",
    "X_val_final = scaler.transform(X_val_final)\n",
    "X_val_final = feature_selector.transform(X_val_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8fe0b24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9591675805193"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain predictions on validation data\n",
    "y_val_predicted = model.predict(X_val_final)\n",
    "\n",
    "# evaluate model training metrics with macro f1 score\n",
    "f1_score(y_val, y_val_predicted, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8997e6",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47293816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST DATA \n",
    "test_df = pd.read_csv('raw_data/balancedtest.csv', index_col = False)\n",
    "test_df = test_df if enable_all_data else test_df.sample(PARTITION_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd783554",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.iloc[:, 1]\n",
    "y_test = test_df.iloc[:, 0]\n",
    "\n",
    "# print(X_test.head())\n",
    "# print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "337bcfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess test data to match steps on training data\n",
    "X_test_unprocessed = X_test\n",
    "X_test_ls = X_test.apply(preprocess)\n",
    "X_test_sentence = X_test_ls.apply(lambda sentence: ' '.join(sentence))\n",
    "\n",
    "X_test = X_test_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0863f80a",
   "metadata": {},
   "source": [
    "### Feature Engineering (Test Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d0afa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature engineering on X_test\n",
    "test_tfidf_word2vec = tfidf_vectorizer_word2vec.transform(X_test)\n",
    "non_zero_counts = test_tfidf_word2vec.getnnz(axis=1)\n",
    "\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "X_test_tf = tf_vectorizer.transform(X_test)\n",
    "X_test_word2vec = word2vec_select_k_best_sum(test_tfidf_word2vec, non_zero_counts)\n",
    "X_test_count_pp = X_test.apply(count_personal_pronouns).to_numpy().reshape(-1, 1)\n",
    "X_test_count_words = X_test_unprocessed.apply(count_words).to_numpy().reshape(-1, 1)\n",
    "X_test_count_uppercase = X_test_unprocessed.apply(count_uppercase).to_numpy().reshape(-1, 1)\n",
    "X_test_flesch = X_test_unprocessed.apply(flesch_kincaid).to_numpy().reshape(-1, 1)\n",
    "X_test_count_verbs = count_verbs(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "891b1b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidation of feature transformations into single vector\n",
    "X_test_final = hstack([X_test_tfidf, X_test_tf, X_test_word2vec, X_test_count_pp, X_test_count_words, X_test_count_uppercase, X_test_flesch, X_test_count_verbs])\n",
    "X_test_final = scaler.transform(X_test_final)\n",
    "X_test_final = feature_selector.transform(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8f9170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain predictions on test data\n",
    "y_pred = model.predict(X_test_final)\n",
    "\n",
    "# evaluate model training metrics with macro f1 score\n",
    "test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "test_accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "56999da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.72557519,\tTest Precision: 0.74673012,\tTest Recall: 0.72562127,\tTest F1: 0.71580559\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Accuracy: {test_accuracy:.8f},\\tTest Precision: {test_precision:.8f},\\tTest Recall: {test_recall:.8f},\\tTest F1: {test_f1:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "906da47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "with open('LogisticRegression.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c15ce6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "with open('LogisticRegression.pkl', 'rb') as f:\n",
    "    saved_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12b2f99",
   "metadata": {},
   "source": [
    "### Extra code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5544f381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997899655896392"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # do prediction on training data\n",
    "# y_train_predicted = model.predict(X_train)\n",
    "\n",
    "# # obtain training f1 score\n",
    "# f1_score(y_train, y_train_predicted, average='macro') # TODO this tests the model on its already trained set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "497ec894",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '  football insiders calling unexpectedly severe punishment national football league sentenced new england patriots quarterback tom brady year new york jets his role called deflategate scandal punishment drew howls protest patriots fans management calling harshest league history n.f.l. commissioner roger goodell defended decision necessary deterrent need send message league zero tolerance cheating goodell said believe year playing quarterback jets sends message loud clear brady reportedly state shock heard news his punishment later met reporters hastily called press conference frequently verge tears going fight decision fibre my brady said america nt force person play jets sports bar manhattan reaction impending arrival jets longtime nemesis muted jets fan observed look bradys dick nt deserve'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# obtain predictions on test data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# obtain test f1 score\u001b[39;00m\n\u001b[0;32m      5\u001b[0m f1_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Hong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:351\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    350\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 351\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    353\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Hong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:332\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    329\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    330\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 332\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    333\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32mc:\\Users\\Hong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\Hong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:997\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    995\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 997\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1001\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:521\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    519\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 521\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    523\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32mc:\\Users\\Hong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1022\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1022\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   1024\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '  football insiders calling unexpectedly severe punishment national football league sentenced new england patriots quarterback tom brady year new york jets his role called deflategate scandal punishment drew howls protest patriots fans management calling harshest league history n.f.l. commissioner roger goodell defended decision necessary deterrent need send message league zero tolerance cheating goodell said believe year playing quarterback jets sends message loud clear brady reportedly state shock heard news his punishment later met reporters hastily called press conference frequently verge tears going fight decision fibre my brady said america nt force person play jets sports bar manhattan reaction impending arrival jets longtime nemesis muted jets fan observed look bradys dick nt deserve'"
     ]
    }
   ],
   "source": [
    "# # obtain predictions on test data\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # obtain test f1 score\n",
    "# f1_score(y_test, y_pred, average= 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e9e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyper Parameter tuning with GridSearchCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676ff02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Jian Hui end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f13bebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### <Group Member's name> start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0b8584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group member's code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7d8f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8843a535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e911876",
   "metadata": {},
   "outputs": [],
   "source": [
    "### <Group Member's name> end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee8d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba8cfd39",
   "metadata": {},
   "source": [
    "# DEPRECATED FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f121ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Sentiment analysis\n",
    "# def sentiment_analysis(sentence):\n",
    "#     doc = spacy_model(sentence)\n",
    "#     return doc._.blob.polarity\n",
    "\n",
    "# X_train_sent_ana = X_train_unprocessed.apply(sentiment_analysis).to_numpy().reshape(-1, 1)\n",
    "\n",
    "# ## Analysis of sentiment feature\n",
    "# count_analysis(X_train_sent_ana, y_train)\n",
    "\n",
    "# # Save sentiment analysis output\n",
    "# pd_sent_ana = pd.DataFrame(X_train_sent_ana, columns=[\"Sentiment\"])\n",
    "# compression_opts = dict(method='zip', archive_name='sent_ana.csv')\n",
    "# pd_sent_ana.to_csv('features/sent_ana.zip', index=False, compression=compression_opts)\n",
    "\n",
    "# 3) Subjectivity analysis \n",
    "# def subjectivity_analysis(sentence):\n",
    "#     doc = spacy_model(sentence)\n",
    "#     return doc._.blob.subjectivity\n",
    "\n",
    "# X_train_subj_ana = X_train_unprocessed.apply(subjectivity_analysis).to_numpy().reshape(-1, 1)\n",
    "\n",
    "# ## Analysis of subjectivity feature\n",
    "# count_analysis(X_train_subj_ana, y_train)\n",
    "\n",
    "# # Save sentiment analysis output\n",
    "# pd_subj_ana = pd.DataFrame(X_train_subj_ana, columns=[\"Subjectivity\"])\n",
    "# compression_opts = dict(method='zip', archive_name='subj_ana.csv')\n",
    "# pd_subj_ana.to_csv('features/subj_ana.zip', index=False, compression=compression_opts)\n",
    "\n",
    "# 4) Number of exclamation and question marks (pre-analyze first)\n",
    "# def count_exclamation_marks(sentence):\n",
    "#     return len(re.findall(r'\\!', sentence))\n",
    "\n",
    "# def count_question_marks(sentence):\n",
    "#     return len(re.findall(r'\\?', sentence))\n",
    "\n",
    "# X_train_count_ex = X_train.apply(count_exclamation_marks).to_numpy().reshape(-1, 1)\n",
    "# X_train_count_qn = X_train.apply(count_question_marks).to_numpy().reshape(-1, 1)\n",
    "\n",
    "# count_analysis(X_train_count_ex, y_train, \"Exclamation mark\")\n",
    "# count_analysis(X_train_count_qn, y_train, \"Question mark\")\n",
    "\n",
    "# 5) Count number of sentences\n",
    "# def count_sentences(sentences):\n",
    "#     return len(nltk.sent_tokenize(sentences)) \n",
    "\n",
    "# X_train_count_sentences = X_train.apply(count_sentences).to_numpy().reshape(-1, 1)\n",
    "# count_analysis_scatter(X_train_count_sentences, y_train, \"sentence_count\")\n",
    "\n",
    "# 7) text2emotion (takes too around 6 hours)\n",
    "# def emotion_vector(sentences):\n",
    "#     res = np.zeros((len(sentences), 5)) # Angry, Fear, Happy, Sad, Surprise\n",
    "#     row = 0\n",
    "#     for sentence in sentences:\n",
    "#         d = te.get_emotion(sentence)\n",
    "#         emotion_sorted = sorted(d.items(), key=lambda tup: tup[0])\n",
    "#         values = np.fromiter(map(lambda tup: tup[1], emotion_sorted), dtype=float)\n",
    "#         res[row] = values\n",
    "#         row += 1\n",
    "#     return res\n",
    "\n",
    "# X_train_emotion = emotion_vector(X_train_unprocessed).to_numpy().reshape(-1, 1)\n",
    "# count_analysis_scatter(X_train_emotion[:, 0], y_train, \"emotion_angry\")\n",
    "# count_analysis_scatter(X_train_emotion[:, 1], y_train, \"emotion_fear\")\n",
    "# count_analysis_scatter(X_train_emotion[:, 2], y_train, \"emotion_happy\")\n",
    "# count_analysis_scatter(X_train_emotion[:, 3], y_train, \"emotion_sad\")\n",
    "# count_analysis_scatter(X_train_emotion[:, 4], y_train, \"emotion_surprise\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510d5573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd6dc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55507397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc09d284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aab69b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeb89dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a87c63b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596eb93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a0c61a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
