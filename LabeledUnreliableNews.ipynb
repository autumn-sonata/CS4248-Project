{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71c7e43e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5116044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN SETUP.SH BEFORE RUNNING THIS IPYNB\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB # Naive Bayes Classifier\n",
    "from sklearn.linear_model import LogisticRegression # Logistic Regression Classifier\n",
    "from sklearn.neural_network import MLPClassifier # Multi Layer Perceptron, simple Neural Network\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import ADASYN, RandomOverSampler\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b81c927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42 # seed random state for comparison, testing\n",
    "PARTITION_SIZE = 500 # Adjust lower if potato PC and higher if gaming rig or want results closer to actual\n",
    "enable_all_data = True # SET TO FALSE IF PREPROCESSING TAKES A LONG TIME (True = test on PARTITION_SIZE training and PARTITION_SIZE testing samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f33710",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48002adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Jian Hui start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a8090b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A little less than a decade ago, hockey fans w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The writers of the HBO series The Sopranos too...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Despite claims from the TV news outlet to offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>After receiving 'subpar' service and experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentence\n",
       "0      1  A little less than a decade ago, hockey fans w...\n",
       "1      1  The writers of the HBO series The Sopranos too...\n",
       "2      1  Despite claims from the TV news outlet to offe...\n",
       "3      1  After receiving 'subpar' service and experienc...\n",
       "4      1  After watching his beloved Seattle Mariners pr..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('raw_data/fulltrain.csv', index_col = False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "641253f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    A little less than a decade ago, hockey fans w...\n",
      "1    The writers of the HBO series The Sopranos too...\n",
      "2    Despite claims from the TV news outlet to offe...\n",
      "3    After receiving 'subpar' service and experienc...\n",
      "4    After watching his beloved Seattle Mariners pr...\n",
      "Name: Sentence, dtype: object\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: Label, dtype: int64\n",
      "48854\n",
      "48854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3    17870\n",
       "1    14047\n",
       "4     9995\n",
       "2     6942\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df if enable_all_data else df.sample(n=PARTITION_SIZE, random_state=SEED)\n",
    "X_train = df.iloc[:, 1] \n",
    "y_train = df.iloc[:, 0]\n",
    "\n",
    "print(X_train.head())\n",
    "print(y_train.head())\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9285af76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing data: tokenize the text for NLP Machine Learning\n",
    "# Eric\n",
    "spacy_preprocess_model = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess(sentence):\n",
    "    '''\n",
    "    Preprocessing strategies:\n",
    "    1) Tokenization\n",
    "    2) Punctuation removal\n",
    "    3) Stopword removal\n",
    "    4) Lemmatization\n",
    "    5) Lowercase\n",
    "    '''\n",
    "    tokens = spacy_preprocess_model(sentence)\n",
    "    ls_sentence = [token.lemma_ for token in tokens if not token.is_punct and not token.is_stop]\n",
    "    return ls_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ab75c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be used by features for feature extraction:\n",
    "X_train_ls = X_train.apply(preprocess)\n",
    "X_train_sentence = X_train_ls.apply(lambda sentence: ' '.join(sentence))\n",
    "\n",
    "# X_train_ls = X_train\n",
    "# X_train_sentence = X_train_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f090821c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    little decade ago hockey fan bless slate game ...\n",
       "1    writer HBO series Sopranos take daring storyte...\n",
       "2    despite claim tv news outlet offer nonstop new...\n",
       "3    receive subpar service experience unusually lo...\n",
       "4    watch beloved Seattle Mariners prevail San Die...\n",
       "Name: Sentence, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quickload pre-processed data\n",
    "X_train = pd.read_csv('raw_data/lemma_strip_punct_stop.csv', index_col=False).iloc[:, 0]\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136b5d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pre-processed data\n",
    "# compression_opts = dict(method='zip', archive_name='lemma_strip_punct_stop.csv')\n",
    "# X_train_sentence.to_csv('lemma_strip_punct_stop.zip', index=False, compression=compression_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704b2070",
   "metadata": {},
   "source": [
    "### Train-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b08f33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07ca07b",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3095317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature set:\n",
    "# 1) TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), sublinear_tf=True)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdd8bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) NER? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff0f8f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidation of feature sets into single vector:\n",
    "# Eric\n",
    "X_train = hstack([X_train_tfidf])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ce5211",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b26eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=SEED)\n",
    "X_train, y_train = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a609fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADASYN\n",
    "ada = ADASYN(random_state=SEED)\n",
    "X_train, y_train = ada.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eaf66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTEENN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83844d2d",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07f2107",
   "metadata": {},
   "source": [
    "### Naive Bayes Model [MultinomialNB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c952f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB().fit(X_train, y_train) # fit model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b89589e",
   "metadata": {},
   "source": [
    "### Logistic Regression Model [LogisticRegression]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4879294",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver = 'saga').fit(X_train, y_train) # train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac9bd3c",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4ae2fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature engineering on X_val\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1e6b93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidation of feature sets:\n",
    "X_val = hstack([X_val_tfidf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fe0b24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9487405898448626"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain predictions on validation data\n",
    "y_val_predicted = model.predict(X_val)\n",
    "\n",
    "# evaluate model training metrics with macro f1 score\n",
    "f1_score(y_val, y_val_predicted, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8997e6",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47293816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST DATA \n",
    "test_df = pd.read_csv('raw_data/balancedtest.csv', index_col = False)\n",
    "test_df = test_df if enable_all_data else test_df.sample(PARTITION_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd783554",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.iloc[:, 1]\n",
    "y_test = test_df.iloc[:, 0]\n",
    "\n",
    "# print(X_test.head())\n",
    "# print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "337bcfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess test data to match steps on training data\n",
    "X_test_ls = X_test.apply(preprocess)\n",
    "X_test_sentence = X_test_ls.apply(lambda sentence: ' '.join(sentence))\n",
    "\n",
    "# X_test_ls = X_test\n",
    "# X_test_sentence = X_test_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0863f80a",
   "metadata": {},
   "source": [
    "### Feature Engineering (Test Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d0afa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) TF-IDF\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "891b1b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidation of feature transformations into single vector\n",
    "# Eric\n",
    "X_test = hstack([X_test_tfidf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8f9170c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4195495337848855"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain predictions on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaluate model training metrics with macro f1 score\n",
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c4ce93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5544f381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do prediction on training data\n",
    "y_train_predicted = lr_clf.predict(X_train)\n",
    "\n",
    "# obtain training f1 score\n",
    "f1_score(y_train, y_train_predicted, average='macro') # TODO this tests the model on its already trained set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cc6c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain predictions on test data\n",
    "y_pred = lr_clf.predict(X_test)\n",
    "\n",
    "# obtain test f1 score\n",
    "f1_score(y_test, y_pred, average= 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e9e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyper Parameter tuning with GridSearchCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676ff02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Jian Hui end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f13bebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### <Group Member's name> start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0b8584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group member's code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7d8f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8843a535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e911876",
   "metadata": {},
   "outputs": [],
   "source": [
    "### <Group Member's name> end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee8d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f121ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510d5573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd6dc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55507397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc09d284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aab69b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeb89dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a87c63b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596eb93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a0c61a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
