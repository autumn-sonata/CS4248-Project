{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71c7e43e",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5116044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN SETUP.SH BEFORE RUNNING THIS IPYNB\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB # Naive Bayes Classifier\n",
    "from sklearn.linear_model import LogisticRegression # Logistic Regression Classifier\n",
    "from sklearn.neural_network import MLPClassifier # Multi Layer Perceptron, simple Neural Network\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "import spacy\n",
    "\n",
    "# seed random state for comparison, testing\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f33710",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48002adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Jian Hui start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a8090b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('raw_data/fulltrain.csv', index_col = False)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f090821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quickload pre-processed data\n",
    "df = pd.read_csv('raw_data/lemma_strip_punct_stop.csv', index_col = False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "641253f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    A little less than a decade ago, hockey fans w...\n",
      "1    The writers of the HBO series The Sopranos too...\n",
      "2    Despite claims from the TV news outlet to offe...\n",
      "3    After receiving 'subpar' service and experienc...\n",
      "4    After watching his beloved Seattle Mariners pr...\n",
      "Name: Sentence, dtype: object\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: Label, dtype: int64\n",
      "48854\n",
      "48854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3    17870\n",
       "1    14047\n",
       "4     9995\n",
       "2     6942\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARTITION_SIZE = 500 # Adjust lower if potato PC and higher if gaming rig or want results closer to actual\n",
    "enable_all_data = True # SET TO FALSE IF PREPROCESSING TAKES A LONG TIME (True = test on PARTITION_SIZE training and PARTITION_SIZE testing samples)\n",
    "\n",
    "df = df if enable_all_data else df.sample(n=PARTITION_SIZE, random_state=SEED)\n",
    "X_train = df.iloc[:, 1] \n",
    "y_train = df.iloc[:, 0]\n",
    "\n",
    "print(X_train.head())\n",
    "print(y_train.head())\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9285af76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing data: tokenize the text for NLP Machine Learning\n",
    "# Eric\n",
    "spacy_preprocess_model = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess(sentence):\n",
    "    '''\n",
    "    Preprocessing strategies:\n",
    "    1) Tokenization\n",
    "    2) Punctuation removal\n",
    "    3) Stopword removal\n",
    "    4) Lemmatization\n",
    "    5) Lowercase\n",
    "    '''\n",
    "    tokens = spacy_preprocess_model(sentence)\n",
    "    ls_sentence = [token.lemma_ for token in tokens if not token.is_punct and not token.is_stop]\n",
    "    return ls_sentence\n",
    "\n",
    "# To be used by features for feature extraction:\n",
    "X_train_ls = X_train.apply(preprocess)\n",
    "X_train_sentence = X_train_ls.apply(lambda sentence: ' '.join(sentence))\n",
    "\n",
    "# X_train_ls = X_train\n",
    "# X_train_sentence = X_train_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5ac114",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.head())\n",
    "print(X_train_ls.head())\n",
    "print(X_train_sentence.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136b5d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_opts = dict(method='zip', archive_name='lemma_strip_punct_stop.csv')\n",
    "X_train_sentence.to_csv('lemma_strip_punct_stop.zip', index=False, compression=compression_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07ca07b",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3095317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature set:\n",
    "# 1) TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), sublinear_tf=True)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdd8bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) NER? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0f8f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidation of feature sets into single vector:\n",
    "# Eric\n",
    "X_train = hstack([X_train_tfidf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c952f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Model\n",
    "nb_clf = MultinomialNB().fit(X_train, y_train) # fit model\n",
    "\n",
    "# obtain predictions on training data\n",
    "y_train_predicted = nb_clf.predict(X_train)\n",
    "\n",
    "# evaluate model training metrics with macro f1 score\n",
    "f1_score(y_train, y_train_predicted, average='macro') # TODO this tests the model on its already trained set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47293816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST DATA \n",
    "test_df = pd.read_csv('raw_data/balancedtest.csv', index_col = False)\n",
    "test_df = test_df if enable_all_data else test_df.sample(PARTITION_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd783554",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.iloc[:, 1]\n",
    "y_test = test_df.iloc[:, 0]\n",
    "\n",
    "# print(X_test.head())\n",
    "# print(y_test.head())\n",
    "\n",
    "# Preprocess test data to match steps on training data\n",
    "X_test_ls = X_test.apply(preprocess)\n",
    "X_test_sentence = X_test_ls.apply(lambda sentence: ' '.join(sentence))\n",
    "\n",
    "# X_test_ls = X_test\n",
    "# X_test_sentence = X_test_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0863f80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature transformation for test data\n",
    "\n",
    "# 1) TF-IDF\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_sentence)\n",
    "\n",
    "# Consolidation of feature transformations into single vector\n",
    "# Eric\n",
    "X_test = hstack([X_test_tfidf])\n",
    "\n",
    "y_pred = nb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f9170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test f1 Score\n",
    "# evaluate model training metrics with macro f1 score\n",
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4879294",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(solver = 'saga')\n",
    "lr_clf.fit(X_train, y_train) # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5544f381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do prediction on training data\n",
    "y_train_predicted = lr_clf.predict(X_train)\n",
    "\n",
    "# obtain training f1 score\n",
    "f1_score(y_train, y_train_predicted, average='macro') # TODO this tests the model on its already trained set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cc6c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain predictions on test data\n",
    "y_pred = lr_clf.predict(X_test)\n",
    "\n",
    "# obtain test f1 score\n",
    "f1_score(y_test, y_pred, average= 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e9e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyper Parameter tuning with GridSearchCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676ff02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Jian Hui end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f13bebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### <Group Member's name> start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0b8584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group member's code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7d8f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8843a535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e911876",
   "metadata": {},
   "outputs": [],
   "source": [
    "### <Group Member's name> end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee8d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f121ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510d5573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd6dc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55507397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc09d284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aab69b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeb89dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a87c63b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596eb93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a0c61a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
