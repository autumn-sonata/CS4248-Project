{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "class TextCNN():\n",
    "    \"\"\"\n",
    "                    -> convolutional, max-pooling (stride 2, 128 filters) ->\n",
    "    Embedding layer -> convolutional, max-pooling (stride 3, 128 filters) -> 1 dense layer -> softmax layer.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "      self, sequence_length, num_classes, vocab_size,\n",
    "      embedding_size, dropout_prob, num_filters):\n",
    "       \n",
    "      inputs = keras.Input(shape=(sequence_length,), dtype=\"int64\")\n",
    "      x = layers.Embedding(vocab_size, embedding_size)(inputs)\n",
    "      conv1 = layers.Conv1D(num_filters, 2, activation='relu')(x)\n",
    "      conv1pooled = layers.GlobalMaxPooling1D()(conv1)\n",
    "      conv2 = layers.Conv1D(num_filters, 3, activation='relu')(x)\n",
    "      conv2pooled = layers.GlobalMaxPooling1D()(conv2)\n",
    "      combined = layers.concatenate([conv1pooled, conv2pooled])\n",
    "      x = layers.Dense(\n",
    "         units=64, \n",
    "         activation='relu', \n",
    "        #  bias_regularizer=regularizers.L2(1e-4),\n",
    "         activity_regularizer=regularizers.L2(1e-7)\n",
    "        )(combined)\n",
    "      x = layers.Dropout(dropout_prob, seed=SEED)(x)\n",
    "      outputs = layers.Dense(num_classes, activation='softmax')(x)    \n",
    "      self.model = keras.Model(inputs, outputs, name=\"CNN\")\n",
    "      self.model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=[keras.metrics.CategoricalAccuracy(), \n",
    "                           keras.metrics.F1Score(average=None, threshold=None, name=\"f1_score\", dtype=None),\n",
    "                          #  keras.metrics.AUC(multi_label=True, num_labels=num_classes,)\n",
    "                          ]\n",
    "                  )\n",
    "\n",
    "    def getModel(self):\n",
    "        return self.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import utils\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, tokenizer_from_json\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Parameters\n",
    "# ==================================================\n",
    "\n",
    "# Model Hyperparameters\n",
    "embedding_dim = 128\n",
    "num_filters = 128\n",
    "dropout_prob = 0.4 \n",
    "l2_reg_lambda = 0.0\n",
    "max_seq = 1000\n",
    "num_classes = 4\n",
    "\n",
    "# Training parameters\n",
    "epochs = 2\n",
    "\n",
    "# Misc Parameters\n",
    "allow_soft_placement = True\n",
    "log_device_placement = False\n",
    "\n",
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "\n",
    "def generateTokenizer(file):\n",
    "    df_processed = pd.read_csv(file, index_col = False)\n",
    "    if \"Sentence\" in df_processed:\n",
    "        tokenizer.fit_on_texts(df_processed[\"Sentence\"].str.lower())\n",
    "    elif \"sentence\" in df_processed:\n",
    "        tokenizer.fit_on_texts(df_processed[\"sentence\"].str.lower())\n",
    "    else:\n",
    "        df_processed.loc[-1] = df_processed.columns  \n",
    "        df_processed.index = df_processed.index + 1  # shifting index\n",
    "        df_processed.sort_index(inplace=True) \n",
    "        df_processed.columns = [*df_processed.columns[:-1], 'Sentence']\n",
    "        tokenizer.fit_on_texts(df_processed[\"Sentence\"].str.lower())\n",
    "        \n",
    "    tokenizer_json = tokenizer.to_json()\n",
    "    with io.open(f'{os.path.basename(file)}_tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(tokenizer_json, ensure_ascii=False))\n",
    "    return f'{os.path.basename(file)}_tokenizer.json'\n",
    "\n",
    "\n",
    "def preprocess(file, tokenizer, df=None):\n",
    "    # Data Preparation\n",
    "    # ==================================================\n",
    "    if df is None:\n",
    "        df = pd.read_csv(file, index_col = False)\n",
    "\n",
    "    with open(tokenizer) as f:\n",
    "        data = json.load(f)\n",
    "        tokenizer = tokenizer_from_json(data)\n",
    "    \n",
    "    word_index = tokenizer.word_index\n",
    "    # print(word_index)\n",
    "    \n",
    "    if \"Sentence\" in df:\n",
    "        sequences = tokenizer.texts_to_sequences(df[\"Sentence\"].str.lower())\n",
    "    elif \"sentence\" in df:\n",
    "        sequences = tokenizer.texts_to_sequences(df[\"sentence\"].str.lower())\n",
    "    else:\n",
    "        print(\"Check columns of data\")\n",
    "   \n",
    "    padded = pad_sequences(sequences, padding='post', maxlen=max_seq)\n",
    "    if \"Label\" in df:\n",
    "        y_train_one_hot = utils.to_categorical(df[\"Label\"]-1, num_classes=4)\n",
    "    elif \"label\" in df:\n",
    "        y_train_one_hot = utils.to_categorical(df[\"label\"]-1, num_classes=4)\n",
    "\n",
    "    print(\"Vocabulary Size: {:d}\".format(len(word_index)))\n",
    "    return padded, y_train_one_hot, word_index \n",
    "\n",
    "\n",
    "def train(x, y, word_index, epochs, filename=\"CNN_model.keras\", validation=False):\n",
    "    # Training\n",
    "    # ==================================================\n",
    "    model = TextCNN(max_seq, num_classes, len(word_index), embedding_dim, dropout_prob, num_filters).getModel()\n",
    "    print(model.summary())\n",
    "\n",
    "    #Used when training on the base LUN dataset, everything else is just the full data \n",
    "    if validation:\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=SEED)\n",
    "        model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=epochs)\n",
    "    else:\n",
    "        model.fit(x, y, epochs=epochs)\n",
    "    model.save(filename)\n",
    "\n",
    "    if validation: \n",
    "        print(\"===============================Model Performance on Validation Set======================================\")\n",
    "        y_val = np.argmax(y_val, axis=1) # Convert probabilities to index\n",
    "        y_pred = np.argmax(model.predict(x_val), axis=1)\n",
    "        print(classification_report(y_val, y_pred, digits=8))\n",
    "\n",
    "    print(\"===============================Model Performance on Full Training Set======================================\")\n",
    "    y = np.argmax(y, axis=1) # Convert probabilities to index\n",
    "    y_pred = np.argmax(model.predict(x), axis=1)\n",
    "    print(\"Prediction distribution:\")\n",
    "    print(pd.Series(y_pred).value_counts())\n",
    "    print(classification_report(y, y_pred, digits=8))\n",
    "    \n",
    "    return model\n",
    "    \n",
    "def test(file, model, tokenizer, df=None):\n",
    "    x_test, y_test, _ = preprocess(file, tokenizer=tokenizer, df=df)\n",
    "    test_scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "    print(test_scores)\n",
    "\n",
    "    y_test = np.argmax(y_test, axis=1) # Convert probabilities to index\n",
    "    y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "    print(\"Prediction distribution:\")\n",
    "    print(pd.Series(y_pred).value_counts())\n",
    "    print(classification_report(y_test, y_pred, digits=8))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base LUN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add label column from fulltrain to processed csv \n",
    "\n",
    "#if fulltrain doesnt have the label, sentence columns yet\n",
    "df_train = pd.read_csv(\"../raw_data/fulltrain.csv\")\n",
    "if \"Sentence\" not in df_train.columns: \n",
    "    df_train.loc[-1] = df_train.columns  \n",
    "    df_train.index = df_train.index + 1  # shifting index\n",
    "    df_train.sort_index(inplace=True) \n",
    "    df_train.columns = [\"Label\", \"Sentence\"]\n",
    "    df_train.to_csv('../raw_data/fulltrain.csv',index=False)\n",
    "\n",
    "df_test = pd.read_csv(\"../raw_data/balancedtest.csv\")\n",
    "if \"Sentence\" not in df_test.columns: \n",
    "    df_test.loc[-1] = df_test.columns  \n",
    "    df_test.index = df_test.index + 1  # shifting index\n",
    "    df_test.sort_index(inplace=True) \n",
    "    df_test.columns = [\"Label\", \"Sentence\"]\n",
    "    df_test.to_csv('../raw_data/balancedtest.csv',index=False)\n",
    "\n",
    "df = pd.read_csv(\"../preprocessed_data/strip_punct_stop.csv\", index_col=False)\n",
    "df_modified = pd.concat([df_train[\"Label\"], df[\"Sentence\"]], axis=1, ignore_index=True)\n",
    "df_modified.columns = [\"Label\", \"Sentence\"]\n",
    "df_modified[\"Label\"] = pd.to_numeric(df_modified[\"Label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"strip_punct_stop.csv_tokenizer.json\"):\n",
    "    generateTokenizer(\"../preprocessed_data/strip_punct_stop.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 229614\n"
     ]
    }
   ],
   "source": [
    "x, y, word_index = preprocess(file=\"\", tokenizer=\"strip_punct_stop.csv_tokenizer.json\", df=df_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"CNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">29,390,592</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">999</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">998</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooli… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │ \u001b[38;5;34m29,390,592\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m999\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m32,896\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m998\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m49,280\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_max_pooli… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,448\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m260\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,489,476</span> (112.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,489,476\u001b[0m (112.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,489,476</span> (112.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,489,476\u001b[0m (112.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/2\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 195ms/step - categorical_accuracy: 0.7792 - f1_score: 0.7472 - loss: 0.5439 - val_categorical_accuracy: 0.9582 - val_f1_score: 0.9549 - val_loss: 0.1144\n",
      "Epoch 2/2\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 191ms/step - categorical_accuracy: 0.9809 - f1_score: 0.9795 - loss: 0.0618 - val_categorical_accuracy: 0.9720 - val_f1_score: 0.9696 - val_loss: 0.0829\n",
      "===============================Model Performance on Validation Set======================================\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.96113074 0.97386323 0.96745510      2793\n",
      "           1  0.96800000 0.97082422 0.96941005      1371\n",
      "           2  0.98658093 0.98383050 0.98520380      3587\n",
      "           3  0.96380090 0.94900990 0.95634822      2020\n",
      "\n",
      "    accuracy                      0.97195783      9771\n",
      "   macro avg  0.96987815 0.96938196 0.96960429      9771\n",
      "weighted avg  0.97198954 0.97195783 0.97194890      9771\n",
      "\n",
      "===============================Model Performance on Full Training Set======================================\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step\n",
      "Prediction distribution:\n",
      "2    17862\n",
      "0    14079\n",
      "3     9967\n",
      "1     6946\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.99218695 0.99444721 0.99331579     14047\n",
      "           1  0.99352145 0.99409392 0.99380760      6942\n",
      "           2  0.99703281 0.99658646 0.99680958     17870\n",
      "           3  0.99227451 0.98949475 0.99088268      9995\n",
      "\n",
      "    accuracy                      0.99416629     48854\n",
      "   macro avg  0.99375393 0.99365558 0.99370391     48854\n",
      "weighted avg  0.99416703 0.99416629 0.99416586     48854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#This model has validation\n",
    "model = train(x, y, word_index, epochs, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================Model Performance on Test Set======================================\n",
      "Vocabulary Size: 229614\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - categorical_accuracy: 0.5094 - f1_score: 0.3400 - loss: 2.3223\n",
      "[1.883949875831604, 0.6196666955947876, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.6621391 , 0.31163704, 0.6228495 , 0.78520435], dtype=float32)>]\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "Prediction distribution:\n",
      "2    1517\n",
      "3     791\n",
      "0     428\n",
      "1     264\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.91121495 0.52000000 0.66213922       750\n",
      "           1  0.59848485 0.21066667 0.31163708       750\n",
      "           2  0.46539222 0.94133333 0.62284958       750\n",
      "           3  0.76485461 0.80666667 0.78520441       750\n",
      "\n",
      "    accuracy                      0.61966667      3000\n",
      "   macro avg  0.68498666 0.61966667 0.59545757      3000\n",
      "weighted avg  0.68498666 0.61966667 0.59545757      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"CNN_model.keras\")\n",
    "print(\"===============================Model Performance on Test Set======================================\")\n",
    "test(file=\"../raw_data/balancedtest.csv\", model = model, tokenizer=\"strip_punct_stop.csv_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================Model Performance on External Test Set======================================\n",
      "Vocabulary Size: 229614\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - categorical_accuracy: 0.2710 - f1_score: 0.1927 - loss: 4.1349\n",
      "[3.174232244491577, 0.38428571820259094, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.33161572, 0.14755479, 0.41609633, 0.53883135], dtype=float32)>]\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step\n",
      "Prediction distribution:\n",
      "2    7459\n",
      "3    3363\n",
      "0    1934\n",
      "1    1244\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.46587384 0.25742857 0.33161575      3500\n",
      "           1  0.28135048 0.10000000 0.14755481      3500\n",
      "           2  0.30567100 0.65142857 0.41609636      3500\n",
      "           3  0.54980672 0.52828571 0.53883141      3500\n",
      "\n",
      "    accuracy                      0.38428571     14000\n",
      "   macro avg  0.40067551 0.38428571 0.35852458     14000\n",
      "weighted avg  0.40067551 0.38428571 0.35852458     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"===============================Model Performance on External Test Set======================================\")\n",
    "test_df = pd.read_csv(\"../external-dataset/opensources_fakenewscorpus_modified_undersampled.csv\")\n",
    "test_df.loc[-1] = test_df.columns  \n",
    "test_df.index = test_df.index + 1  # shifting index\n",
    "test_df.sort_index(inplace=True) \n",
    "test_df.columns = [\"Label\", \"Sentence\"]\n",
    "test_df[\"Label\"] = pd.to_numeric(test_df[\"Label\"])\n",
    "test(file=\"\", model = model, tokenizer=\"strip_punct_stop.csv_tokenizer.json\", df=test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synonym augmented training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"synonym_augmented_train.csv_tokenizer.json\"):\n",
    "    generateTokenizer(\"../synonym-creation/synonym_augmented_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 334900\n"
     ]
    }
   ],
   "source": [
    "df_synonym = pd.read_csv(\"../synonym-creation/synonym_augmented_train.csv\")\n",
    "df_synonym.loc[-1] = df_synonym.columns  \n",
    "df_synonym.index = df_synonym.index + 1  # shifting index\n",
    "df_synonym.sort_index(inplace=True) \n",
    "df_synonym.columns = [\"Label\", \"Sentence\"]\n",
    "df_synonym[\"Label\"] = pd.to_numeric(df_synonym[\"Label\"])\n",
    "x, y, word_index = preprocess(file=\"\", tokenizer=\"synonym_augmented_train.csv_tokenizer.json\", df=df_synonym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"CNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">42,867,200</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">999</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">998</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooli… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │ \u001b[38;5;34m42,867,200\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m999\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m32,896\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m998\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m49,280\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_max_pooli… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,448\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m260\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,966,084</span> (163.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m42,966,084\u001b[0m (163.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,966,084</span> (163.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m42,966,084\u001b[0m (163.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/2\n",
      "\u001b[1m2458/2458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 250ms/step - categorical_accuracy: 0.8504 - f1_score: 0.8493 - loss: 0.3877\n",
      "Epoch 2/2\n",
      "\u001b[1m2458/2458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m614s\u001b[0m 250ms/step - categorical_accuracy: 0.9927 - f1_score: 0.9927 - loss: 0.0243\n",
      "===============================Model Performance on Full Training Set======================================\n",
      "\u001b[1m2458/2458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step\n",
      "Prediction distribution:\n",
      "3    19684\n",
      "2    19656\n",
      "0    19650\n",
      "1    19638\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.99984733 0.99949128 0.99966927     19657\n",
      "           1  0.99994908 0.99898255 0.99946558     19657\n",
      "           2  0.99954212 0.99949128 0.99951670     19657\n",
      "           3  0.99857752 0.99994913 0.99926286     19657\n",
      "\n",
      "    accuracy                      0.99947856     78628\n",
      "   macro avg  0.99947901 0.99947856 0.99947860     78628\n",
      "weighted avg  0.99947901 0.99947856 0.99947860     78628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#trained on full set\n",
    "model = train(x, y, word_index, epochs, filename=\"CNN_model_augmented_train.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================Model Performance on Test Set======================================\n",
      "Vocabulary Size: 334900\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - categorical_accuracy: 0.5050 - f1_score: 0.3404 - loss: 3.1866\n",
      "[2.4706013202667236, 0.6203333139419556, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.6561461 , 0.35892317, 0.6253968 , 0.7304256 ], dtype=float32)>]\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step\n",
      "Prediction distribution:\n",
      "3    1153\n",
      "2    1140\n",
      "0     454\n",
      "1     253\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.87004405 0.52666667 0.65614618       750\n",
      "           1  0.71146245 0.24000000 0.35892323       750\n",
      "           2  0.51842105 0.78800000 0.62539683       750\n",
      "           3  0.60277537 0.92666667 0.73042564       750\n",
      "\n",
      "    accuracy                      0.62033333      3000\n",
      "   macro avg  0.67567573 0.62033333 0.59272297      3000\n",
      "weighted avg  0.67567573 0.62033333 0.59272297      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"CNN_model_augmented_train.keras\")\n",
    "print(\"===============================Model Performance on Test Set======================================\")\n",
    "test(file=\"../raw_data/balancedtest.csv\", model = model, tokenizer=\"synonym_augmented_train.csv_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================Model Performance on External Test Set======================================\n",
      "Vocabulary Size: 334900\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - categorical_accuracy: 0.3004 - f1_score: 0.2075 - loss: 5.5427\n",
      "[4.077095031738281, 0.4424999952316284, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.38884833, 0.10258618, 0.4837428 , 0.61639184], dtype=float32)>]\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step\n",
      "Prediction distribution:\n",
      "2    5819\n",
      "3    5053\n",
      "0    1988\n",
      "1    1140\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.53672032 0.30485714 0.38884840      3500\n",
      "           1  0.20877193 0.06800000 0.10258621      3500\n",
      "           2  0.38735178 0.64400000 0.48374289      3500\n",
      "           3  0.52167029 0.75314286 0.61639191      3500\n",
      "\n",
      "    accuracy                      0.44250000     14000\n",
      "   macro avg  0.41362858 0.44250000 0.39789235     14000\n",
      "weighted avg  0.41362858 0.44250000 0.39789235     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"===============================Model Performance on External Test Set======================================\")\n",
    "test_df = pd.read_csv(\"../external-dataset/opensources_fakenewscorpus_modified_undersampled.csv\")\n",
    "test_df.loc[-1] = test_df.columns  \n",
    "test_df.index = test_df.index + 1  # shifting index\n",
    "test_df.sort_index(inplace=True) \n",
    "test_df.columns = [\"Label\", \"Sentence\"]\n",
    "test_df[\"Label\"] = pd.to_numeric(test_df[\"Label\"])\n",
    "test(file=\"\", model = model, tokenizer=\"synonym_augmented_train.csv_tokenizer.json\", df=test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add label column from fulltrain to processed csv \n",
    "df = pd.read_csv(\"../NER-masking/NER_masked_train.csv\", index_col=False)\n",
    "if \"Sentence\" not in df.columns: \n",
    "    df_train = pd.read_csv(\"../raw_data/fulltrain.csv\")\n",
    "    df.loc[-1] = df.columns  \n",
    "    df.index = df.index + 1  # shifting index\n",
    "    df.sort_index() \n",
    "    df_NER_train = pd.concat([df_train[\"Label\"], df], axis=1, ignore_index=True)\n",
    "    df_NER_train.columns = [\"Label\", \"Sentence\"]\n",
    "else:\n",
    "    print(\"Skipping\")\n",
    "\n",
    "df = pd.read_csv(\"../NER-masking/NER_masked_test.csv\", index_col=False)\n",
    "if \"Sentence\" not in df.columns: \n",
    "    df_test = pd.read_csv(\"../external-dataset/opensources_fakenewscorpus_modified_undersampled.csv\")\n",
    "    df_test.loc[-1] = df_test.columns  \n",
    "    df_test.index = df_test.index + 1  # shifting index\n",
    "    df_test.sort_index(inplace=True) \n",
    "    df_test.columns = [\"Label\", \"Sentence\"]\n",
    "    df_test[\"Label\"] = pd.to_numeric(df_test[\"Label\"])\n",
    "    df_NER_test = pd.concat([df_test[\"Label\"], df[\"1\"]], axis=1, ignore_index=True)\n",
    "    df_NER_test.columns = [\"Label\", \"Sentence\"]\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"Skipping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"NER_masked_train.csv_tokenizer.json\"):\n",
    "    generateTokenizer(\"../NER-masking/NER_masked_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 367143\n"
     ]
    }
   ],
   "source": [
    "x, y, word_index = preprocess(file=\"\", tokenizer=\"NER_masked_train.csv_tokenizer.json\", df=df_NER_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"CNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_7         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">46,994,304</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">999</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ embedding_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">998</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │ embedding_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooli… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_7         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │ \u001b[38;5;34m46,994,304\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m999\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m32,896\u001b[0m │ embedding_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_15 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m998\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m49,280\u001b[0m │ embedding_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv1d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv1d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_max_pooli… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,448\u001b[0m │ concatenate_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m260\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,093,188</span> (179.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m47,093,188\u001b[0m (179.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,093,188</span> (179.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m47,093,188\u001b[0m (179.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/2\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 272ms/step - categorical_accuracy: 0.8027 - f1_score: 0.7778 - loss: 0.4845\n",
      "Epoch 2/2\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 271ms/step - categorical_accuracy: 0.9758 - f1_score: 0.9738 - loss: 0.0714\n",
      "===============================Model Performance on Full Training Set======================================\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step\n",
      "Prediction distribution:\n",
      "2    14345\n",
      "0    11261\n",
      "3     7938\n",
      "1     5539\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.99751354 0.99813400 0.99782367     11254\n",
      "           1  0.99873623 0.99299946 0.99585959      5571\n",
      "           2  0.99553852 0.99985997 0.99769456     14283\n",
      "           3  0.99949609 0.99485893 0.99717212      7975\n",
      "\n",
      "    accuracy                      0.99736458     39083\n",
      "   macro avg  0.99782110 0.99646309 0.99713749     39083\n",
      "weighted avg  0.99737059 0.99736458 0.99736357     39083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#trained on full set\n",
    "model = train(x, y, word_index, epochs, filename=\"CNN_model_NER.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================Model Performance on Test Set======================================\n",
      "Vocabulary Size: 367143\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - categorical_accuracy: 0.2998 - f1_score: 0.1961 - loss: 3.9014\n",
      "[3.3834574222564697, 0.3578571379184723, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.37073162, 0.10228506, 0.4210625 , 0.42175218], dtype=float32)>]\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step\n",
      "Prediction distribution:\n",
      "2    7135\n",
      "3    3120\n",
      "0    2650\n",
      "1    1095\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.43018868 0.32571429 0.37073171      3500\n",
      "           1  0.21461187 0.06714286 0.10228509      3500\n",
      "           2  0.31380519 0.63971429 0.42106253      3500\n",
      "           3  0.44743590 0.39885714 0.42175227      3500\n",
      "\n",
      "    accuracy                      0.35785714     14000\n",
      "   macro avg  0.35151041 0.35785714 0.32895790     14000\n",
      "weighted avg  0.35151041 0.35785714 0.32895790     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"CNN_model_NER.keras\")\n",
    "print(\"===============================Model Performance on Test Set======================================\")\n",
    "test(file=\"../raw_data/balancedtest.csv\", model = model, tokenizer=\"NER_masked_train.csv_tokenizer.json\", df=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================Model Performance on External Test Set======================================\n",
      "Vocabulary Size: 367143\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - categorical_accuracy: 0.3003 - f1_score: 0.2018 - loss: 3.9042\n",
      "[3.191516160964966, 0.40071427822113037, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.37580135, 0.09808557, 0.44449615, 0.53691113], dtype=float32)>]\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step\n",
      "Prediction distribution:\n",
      "3    5183\n",
      "2    5085\n",
      "0    2583\n",
      "1    1149\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.44250871 0.32657143 0.37580141      3500\n",
      "           1  0.19843342 0.06514286 0.09808561      3500\n",
      "           2  0.37522124 0.54514286 0.44449621      3500\n",
      "           3  0.44973953 0.66600000 0.53691121      3500\n",
      "\n",
      "    accuracy                      0.40071429     14000\n",
      "   macro avg  0.36647573 0.40071429 0.36382361     14000\n",
      "weighted avg  0.36647573 0.40071429 0.36382361     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"===============================Model Performance on External Test Set======================================\")\n",
    "test(file=\"\", model = model, tokenizer=\"NER_masked_train.csv_tokenizer.json\", df=df_NER_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS4248",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
