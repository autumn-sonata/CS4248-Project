{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n",
    "tf.random.set_seed(10)\n",
    "\n",
    "class TextCNN():\n",
    "    \"\"\"\n",
    "                    -> convolutional, max-pooling (stride 3, 128 filters) ->\n",
    "    Embedding layer -> convolutional, max-pooling (stride 4, 128 filters) -> 1 dense layer -> softmax layer.\n",
    "                    -> convolutional, max-pooling (stride 5, 128 filters) ->\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "      self, sequence_length, num_classes, vocab_size,\n",
    "      embedding_size, dropout_prob, num_filters):\n",
    "       \n",
    "      inputs = keras.Input(shape=(sequence_length,), dtype=\"int64\")\n",
    "      x = layers.Embedding(vocab_size, embedding_size)(inputs)\n",
    "      conv1 = layers.Conv1D(num_filters, 2, activation='relu')(x)\n",
    "      conv1pooled = layers.GlobalMaxPooling1D()(conv1)\n",
    "      conv2 = layers.Conv1D(num_filters, 3, activation='relu')(x)\n",
    "      conv2pooled = layers.GlobalMaxPooling1D()(conv2)\n",
    "      # conv3 = layers.Conv1D(num_filters, 4, activation='relu')(x)\n",
    "      # conv3pooled = layers.GlobalMaxPooling1D()(conv3)\n",
    "      combined = layers.concatenate([conv1pooled, conv2pooled])\n",
    "      x = layers.Dense(\n",
    "         units=64, \n",
    "         activation='relu', \n",
    "        #  bias_regularizer=regularizers.L2(1e-4),\n",
    "        #  activity_regularizer=regularizers.L2(1e-6)\n",
    "        )(combined)\n",
    "      x = layers.Dropout(dropout_prob, seed=10)(x)\n",
    "      outputs = layers.Dense(num_classes, activation='softmax')(x)    \n",
    "      self.model = keras.Model(inputs, outputs, name=\"CNN\")\n",
    "      self.model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=[keras.metrics.CategoricalAccuracy(), \n",
    "                           keras.metrics.F1Score(average=None, threshold=None, name=\"f1_score\", dtype=None),\n",
    "                          #  keras.metrics.AUC(multi_label=True, num_labels=num_classes,)\n",
    "                          ]\n",
    "                  )\n",
    "\n",
    "    def getModel(self):\n",
    "        return self.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import utils\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, tokenizer_from_json\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, accuracy_score\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Parameters\n",
    "# ==================================================\n",
    "\n",
    "# Model Hyperparameters\n",
    "embedding_dim = 128\n",
    "num_filters = 128\n",
    "dropout_prob = 0.4 \n",
    "l2_reg_lambda = 0.0\n",
    "max_seq = 1000\n",
    "num_classes = 4\n",
    "\n",
    "# Training parameters\n",
    "epochs = 2\n",
    "\n",
    "# Misc Parameters\n",
    "allow_soft_placement = True\n",
    "log_device_placement = False\n",
    "\n",
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "\n",
    "def generateTokenizer(file):\n",
    "    df_processed = pd.read_csv(file, index_col = False)\n",
    "    if \"Sentence\" in df_processed:\n",
    "        tokenizer.fit_on_texts(df_processed[\"Sentence\"].str.lower())\n",
    "    elif \"sentence\" in df_processed:\n",
    "        tokenizer.fit_on_texts(df_processed[\"sentence\"].str.lower())\n",
    "    else:\n",
    "        print(\"Check columns of data\")\n",
    "    tokenizer_json = tokenizer.to_json()\n",
    "    with io.open(f'{os.path.basename(file)}_tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(tokenizer_json, ensure_ascii=False))\n",
    "    return f'{os.path.basename(file)}_tokenizer.json'\n",
    "\n",
    "\n",
    "def preprocess(file, tokenizer):\n",
    "    # Data Preparation\n",
    "    # ==================================================\n",
    "    df = pd.read_csv(file, index_col = False)\n",
    "\n",
    "    with open(tokenizer) as f:\n",
    "        data = json.load(f)\n",
    "        tokenizer = tokenizer_from_json(data)\n",
    "    \n",
    "    word_index = tokenizer.word_index\n",
    "\n",
    "    \n",
    "    if \"Sentence\" in df:\n",
    "        sequences = tokenizer.texts_to_sequences(df[\"Sentence\"].str.lower())\n",
    "    elif \"sentence\" in df:\n",
    "        sequences = tokenizer.texts_to_sequences(df[\"sentence\"].str.lower())\n",
    "    else:\n",
    "        print(\"Check columns of data\")\n",
    "   \n",
    "    \n",
    "    padded = pad_sequences(sequences, padding='post', maxlen=max_seq)\n",
    "    if \"Label\" in df:\n",
    "        y_train_one_hot = utils.to_categorical(df[\"Label\"]-1, num_classes=4)\n",
    "    elif \"label\" in df:\n",
    "        y_train_one_hot = utils.to_categorical(df[\"label\"]-1, num_classes=4)\n",
    "\n",
    "    print(\"Vocabulary Size: {:d}\".format(len(word_index)))\n",
    "    return padded, y_train_one_hot, word_index \n",
    "\n",
    "\n",
    "def train(x_train, y_train, word_index, epochs, filename=\"CNN_model.keras\"):\n",
    "    # Training\n",
    "    # ==================================================\n",
    "    model = TextCNN(max_seq, num_classes, len(word_index), embedding_dim, dropout_prob, num_filters).getModel()\n",
    "    print(model.summary())\n",
    "    # utils.plot_model(model, \"my_first_model_with_shape_info.png\", show_shapes=True)\n",
    "    # Fit the model using the train and test datasets.\n",
    "    # Since using fulltrain shuffle first else validation will be very low\n",
    "    x_train, y_train = shuffle(x_train, y_train)\n",
    "    model.fit(x_train, y_train, validation_split=0.4, epochs=epochs)\n",
    "    model.save(filename)\n",
    "    print(\"===============================Model Performance on Train Set======================================\")\n",
    "    print(model.evaluate(x_train, y_train, verbose=1))\n",
    "    y_train = np.argmax(y_train, axis=1) # Convert probabilities to index\n",
    "    y_pred = np.argmax(model.predict(x_train), axis=1)\n",
    "    print(classification_report(y_train, y_pred, digits=8))\n",
    "    \n",
    "    return model\n",
    "    \n",
    "def test(file, model, tokenizer):\n",
    "    x_test, y_test, _ = preprocess(file, tokenizer=tokenizer)\n",
    "    test_scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "    print(test_scores)\n",
    "\n",
    "    y_test = np.argmax(y_test, axis=1) # Convert probabilities to index\n",
    "    y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "    print(\"Prediction distribution:\")\n",
    "    print(pd.Series(y_pred).value_counts())\n",
    "    print(classification_report(y_test, y_pred, digits=8))\n",
    "\n",
    "    # test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "    # test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    # print(f'Test Accuracy: {test_accuracy:.8f},\\tTest Precision: {test_precision:.8f},\\tTest Recall: {test_recall:.8f},\\tTest F1: {test_f1:.8f}')\n",
    "\n",
    "    # class_test_precision, class_test_recall, class_test_f1, class_ = precision_recall_fscore_support(y_test, y_pred)\n",
    "    # for i in range(4):\n",
    "    #     print(f'Class {i}:\\tTest Precision: {class_test_precision[i]:.8f},\\tTest Recall: {class_test_recall[i]:.8f},\\tTest f1: {class_test_f1[i]:.8f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add label column from fulltrain to processed csv \n",
    "df = pd.read_csv(\"../strip_punct_stop/strip_punct_stop.csv\", index_col=False)\n",
    "df_train = pd.read_csv(\"../train_and_balancedtest/fulltrain.csv\")\n",
    "df = pd.concat([df_train[\"Label\"], df[\"Sentence\"]], axis=1, ignore_index=True)\n",
    "df.columns = [\"Label\", \"Sentence\"]\n",
    "\n",
    "df.to_csv('../strip_punct_stop/strip_punct_stop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"strip_punct_stop.csv_tokenizer.json\"):\n",
    "    generateTokenizer(\"../strip_punct_stop/strip_punct_stop.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 229614\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, word_index = preprocess(file=\"../strip_punct_stop/strip_punct_stop.csv\", tokenizer=\"strip_punct_stop.csv_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"CNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_7         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">29,390,592</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">999</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ embedding_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">998</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │ embedding_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooli… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_7         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │ \u001b[38;5;34m29,390,592\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m999\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m32,896\u001b[0m │ embedding_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_15 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m998\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m49,280\u001b[0m │ embedding_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv1d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv1d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_max_pooli… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,448\u001b[0m │ concatenate_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m260\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,489,476</span> (112.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,489,476\u001b[0m (112.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,489,476</span> (112.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,489,476\u001b[0m (112.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/2\n",
      "\u001b[1m916/916\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 208ms/step - categorical_accuracy: 0.7456 - f1_score: 0.7103 - loss: 0.6062 - val_categorical_accuracy: 0.9637 - val_f1_score: 0.9607 - val_loss: 0.1021\n",
      "Epoch 2/2\n",
      "\u001b[1m916/916\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 208ms/step - categorical_accuracy: 0.9754 - f1_score: 0.9732 - loss: 0.0749 - val_categorical_accuracy: 0.9691 - val_f1_score: 0.9670 - val_loss: 0.0960\n",
      "===============================Model Performance on Train Set======================================\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - categorical_accuracy: 0.9969 - f1_score: 0.9967 - loss: 0.0109\n",
      "[0.03966376557946205, 0.9874523878097534, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.98436  , 0.9874675, 0.9934358, 0.9811301], dtype=float32)>]\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     14047\n",
      "           1       0.99      0.99      0.99      6942\n",
      "           2       1.00      0.99      0.99     17870\n",
      "           3       0.98      0.98      0.98      9995\n",
      "\n",
      "    accuracy                           0.99     48854\n",
      "   macro avg       0.99      0.99      0.99     48854\n",
      "weighted avg       0.99      0.99      0.99     48854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = train(x_train, y_train, word_index, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================Model Performance on Test Set======================================\n",
      "Vocabulary Size: 229614\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - categorical_accuracy: 0.4848 - f1_score: 0.3297 - loss: 2.0986\n",
      "[1.5907927751541138, 0.6176666617393494, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.64055693, 0.3121951 , 0.6380133 , 0.75866044], dtype=float32)>]\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.92230576 0.49066667 0.64055701       750\n",
      "           1  0.58181818 0.21333333 0.31219512       750\n",
      "           2  0.49702381 0.89066667 0.63801337       750\n",
      "           3  0.66904277 0.87600000 0.75866051       750\n",
      "\n",
      "    accuracy                      0.61766667      3000\n",
      "   macro avg  0.66754763 0.61766667 0.58735650      3000\n",
      "weighted avg  0.66754763 0.61766667 0.58735650      3000\n",
      "\n",
      "2    1344\n",
      "3     982\n",
      "0     399\n",
      "1     275\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"CNN_model_f1_061.keras\")\n",
    "# model = keras.models.load_model(\"CNN_model.keras\")\n",
    "print(\"===============================Model Performance on Test Set======================================\")\n",
    "test(file=\"../train_and_balancedtest/balancedtest.csv\", model = model, tokenizer=\"strip_punct_stop.csv_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================Model Performance on External Test Set======================================\n",
      "Vocabulary Size: 229614\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - categorical_accuracy: 0.2864 - f1_score: 0.2076 - loss: 3.4151\n",
      "[2.5740530490875244, 0.4050000011920929, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.3246326 , 0.20883214, 0.4156037 , 0.5819502 ], dtype=float32)>]\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.41094092 0.26828571 0.32463267      3500\n",
      "           1  0.33354232 0.15200000 0.20883219      3500\n",
      "           2  0.33090724 0.55857143 0.41560374      3500\n",
      "           3  0.53276353 0.64114286 0.58195021      3500\n",
      "\n",
      "    accuracy                      0.40500000     14000\n",
      "   macro avg  0.40203850 0.40500000 0.38275470     14000\n",
      "weighted avg  0.40203850 0.40500000 0.38275470     14000\n",
      "\n",
      "2    5908\n",
      "3    4212\n",
      "0    2285\n",
      "1    1595\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"===============================Model Performance on External Test Set======================================\")\n",
    "test(file=\"../opensources_fakenewscorpus_balancedtest/opensources_fakenewscorpus_modified_undersampled.csv\", model = model, tokenizer=\"strip_punct_stop.csv_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"synonym_augmented_train.csv_tokenizer.json\"):\n",
    "    generateTokenizer(\"../synonym_augmented_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 334900\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, word_index = preprocess(file=\"../synonym_augmented_train.csv\", tokenizer=\"synonym_augmented_train.csv_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"CNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_8         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">42,867,200</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">999</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ embedding_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">998</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │ embedding_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooli… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ concatenate_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_8         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m128\u001b[0m) │ \u001b[38;5;34m42,867,200\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_16 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m999\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m32,896\u001b[0m │ embedding_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_17 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m998\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m49,280\u001b[0m │ embedding_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv1d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv1d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_max_pooli… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,448\u001b[0m │ concatenate_8[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m260\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,966,084</span> (163.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m42,966,084\u001b[0m (163.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,966,084</span> (163.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m42,966,084\u001b[0m (163.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/2\n",
      "\u001b[1m1475/1475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 271ms/step - categorical_accuracy: 0.7961 - f1_score: 0.7936 - loss: 0.5027 - val_categorical_accuracy: 0.9794 - val_f1_score: 0.9794 - val_loss: 0.0633\n",
      "Epoch 2/2\n",
      "\u001b[1m1475/1475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 271ms/step - categorical_accuracy: 0.9856 - f1_score: 0.9857 - loss: 0.0459 - val_categorical_accuracy: 0.9835 - val_f1_score: 0.9835 - val_loss: 0.0538\n",
      "===============================Model Performance on Train Set======================================\n",
      "\u001b[1m2458/2458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - categorical_accuracy: 0.9979 - f1_score: 0.9979 - loss: 0.0075\n",
      "[0.02288159355521202, 0.9930686354637146, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.99195915, 0.9959241 , 0.99267185, 0.9917233 ], dtype=float32)>]\n",
      "\u001b[1m2458/2458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 17ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     19657\n",
      "           1       1.00      0.99      1.00     19657\n",
      "           2       0.99      1.00      0.99     19657\n",
      "           3       0.99      0.99      0.99     19657\n",
      "\n",
      "    accuracy                           0.99     78628\n",
      "   macro avg       0.99      0.99      0.99     78628\n",
      "weighted avg       0.99      0.99      0.99     78628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = train(x_train, y_train, word_index, epochs, filename=\"CNN_model_augmented_train.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================Model Performance on Test Set======================================\n",
      "Vocabulary Size: 334900\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - categorical_accuracy: 0.5845 - f1_score: 0.3759 - loss: 2.0581\n",
      "[1.8109004497528076, 0.6453333497047424, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.6726643 , 0.43396226, 0.6549423 , 0.7367281 ], dtype=float32)>]\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.69928058 0.64800000 0.67266436       750\n",
      "           1  0.74193548 0.30666667 0.43396226       750\n",
      "           2  0.60066741 0.72000000 0.65494239       750\n",
      "           3  0.62043796 0.90666667 0.73672806       750\n",
      "\n",
      "    accuracy                      0.64533333      3000\n",
      "   macro avg  0.66558036 0.64533333 0.62457427      3000\n",
      "weighted avg  0.66558036 0.64533333 0.62457427      3000\n",
      "\n",
      "3    1096\n",
      "2     899\n",
      "0     695\n",
      "1     310\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"CNN_model_augmented_train_f1_064.keras\")\n",
    "# model = keras.models.load_model(\"CNN_model_augmented_train.keras\")\n",
    "print(\"===============================Model Performance on Test Set======================================\")\n",
    "test(file=\"../train_and_balancedtest/balancedtest.csv\", model = model, tokenizer=\"synonym_augmented_train.csv_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================Model Performance on External Test Set======================================\n",
      "Vocabulary Size: 334900\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - categorical_accuracy: 0.3795 - f1_score: 0.2372 - loss: 3.4229\n",
      "[2.9159815311431885, 0.4480714201927185, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.44670042, 0.11510183, 0.4740605 , 0.6170238 ], dtype=float32)>]\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.42966482 0.46514286 0.44670051      3500\n",
      "           1  0.21728787 0.07828571 0.11510187      3500\n",
      "           2  0.43497972 0.52085714 0.47406059      3500\n",
      "           3  0.53540660 0.72800000 0.61702385      3500\n",
      "\n",
      "    accuracy                      0.44807143     14000\n",
      "   macro avg  0.40433475 0.44807143 0.41322171     14000\n",
      "weighted avg  0.40433475 0.44807143 0.41322171     14000\n",
      "\n",
      "3    4759\n",
      "2    4191\n",
      "0    3789\n",
      "1    1261\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"===============================Model Performance on External Test Set======================================\")\n",
    "test(file=\"../opensources_fakenewscorpus_balancedtest/opensources_fakenewscorpus_modified_undersampled.csv\", model = model, tokenizer=\"synonym_augmented_train.csv_tokenizer.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS4248",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
